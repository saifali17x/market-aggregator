// backend/services/WebScraperEngine.js
const { chromium } = require("playwright");
const robotsParser = require("robots-parser");
const axios = require("axios");

class WebScraperEngine {
  constructor(siteConfig, options = {}, logger = console) {
    this.siteConfig = siteConfig;
    this.logger = logger;
    this.options = {
      delay: options.delay || 2000,
      maxRetries: options.maxRetries || 3,
      timeout: options.timeout || 30000,
      userAgent:
        options.userAgent || "Mozilla/5.0 (compatible; ProductScraper/1.0)",
      proxy: process.env.PROXY_URL || options.proxy,
      maxPages: options.maxPages || 10,
      ...options,
    };
    this.browser = null;
    this.robotsTxt = null;
    this.stats = {
      pagesProcessed: 0,
      productsFound: 0,
      productsSuccess: 0,
      productsFailed: 0,
      startTime: Date.now(),
    };
  }

  async initialize() {
    try {
      const browserOptions = {
        headless: process.env.NODE_ENV === "production",
        args: [
          "--no-sandbox",
          "--disable-setuid-sandbox",
          "--disable-dev-shm-usage",
        ],
      };

      if (this.options.proxy) {
        browserOptions.proxy = { server: this.options.proxy };
      }

      this.browser = await chromium.launch(browserOptions);
      this.logger.info?.("WebScraper browser initialized") ||
        console.log("WebScraper browser initialized");

      await this.checkRobotsTxt();
    } catch (error) {
      this.logger.error?.("Failed to initialize WebScraper:", error) ||
        console.error("Failed to initialize WebScraper:", error);
      throw error;
    }
  }

  async checkRobotsTxt() {
    try {
      const robotsUrl = new URL(
        "/robots.txt",
        this.siteConfig.baseUrl || this.siteConfig.startUrl
      ).href;
      const response = await axios.get(robotsUrl, {
        timeout: 10000,
        validateStatus: (status) => status < 500,
      });

      if (response.status === 200) {
        this.robotsTxt = robotsParser(robotsUrl, response.data);
        this.logger.info?.("Robots.txt loaded successfully") ||
          console.log("Robots.txt loaded successfully");
      }
    } catch (error) {
      this.logger.warn?.("Could not fetch robots.txt:", error.message) ||
        console.warn("Could not fetch robots.txt:", error.message);
    }
  }

  isUrlAllowed(url) {
    if (!this.robotsTxt) return true;
    return this.robotsTxt.isAllowed(url, this.options.userAgent);
  }

  async createBrowserPage() {
    const context = await this.browser.newContext({
      userAgent: this.options.userAgent,
      viewport: { width: 1920, height: 1080 },
    });

    const page = await context.newPage();
    page.setDefaultTimeout(this.options.timeout);

    // Block unnecessary resources for faster scraping
    await page.route("**/*", (route) => {
      const resourceType = route.request().resourceType();
      if (["image", "font", "media", "stylesheet"].includes(resourceType)) {
        route.abort();
      } else {
        route.continue();
      }
    });

    return page;
  }

  async extractProductsFromPage(page, url) {
    try {
      const products = [];
      const productElements = await page.$$(this.siteConfig.selectors.product);

      this.logger.info?.(
        "Found ${productElements.length} products on ${url}"
      ) || console.log(`Found ${productElements.length} products on ${url}`);

      for (let i = 0; i < productElements.length; i++) {
        try {
          const product = await this.extractSingleProduct(
            productElements[i],
            url
          );
          if (this.isValidProduct(product)) {
            products.push(product);
            this.stats.productsSuccess++;
          } else {
            this.stats.productsFailed++;
          }
        } catch (error) {
          this.stats.productsFailed++;
          this.logger.warn?.(
            "Failed to extract product ${i + 1}:",
            error.message
          ) ||
            console.warn(`Failed to extract product ${i + 1}:`, error.message);
        }
      }

      this.stats.productsFound += products.length;
      return products;
    } catch (error) {
      this.logger.error?.("Failed to extract products from ${url}:", error) ||
        console.error(`Failed to extract products from ${url}:`, error);
      return [];
    }
  }

  async extractSingleProduct(element, sourceUrl) {
    const product = {
      id: null, // Will be generated by database
      title: null,
      price: null,
      currency: "USD",
      imageUrl: null,
      productUrl: null,
      description: null,
      brand: null,
      category: null,
      availability: null,
      rating: null,
      reviewCount: null,
      sourceUrl,
      siteName: this.siteConfig.name,
      scrapedAt: new Date(),
      metadata: {},
    };

    // Extract basic fields
    await this.extractField(
      element,
      "title",
      this.siteConfig.selectors.title,
      product
    );
    await this.extractField(
      element,
      "price",
      this.siteConfig.selectors.price,
      product,
      this.normalizePrice
    );
    await this.extractField(
      element,
      "imageUrl",
      this.siteConfig.selectors.image,
      product,
      (url) => this.normalizeUrl(url, sourceUrl)
    );

    // Extract product URL if available
    if (this.siteConfig.selectors.productUrl) {
      const linkElement = await element.$(this.siteConfig.selectors.productUrl);
      if (linkElement) {
        const href = await linkElement.getAttribute("href");
        product.productUrl = this.normalizeUrl(href, sourceUrl);
      }
    }

    // Extract custom fields
    if (this.siteConfig.selectors.custom) {
      for (const [key, selector] of Object.entries(
        this.siteConfig.selectors.custom
      )) {
        await this.extractField(element, key, selector, product);
      }
    }

    // Extract metadata fields
    if (this.siteConfig.selectors.metadata) {
      for (const [key, selector] of Object.entries(
        this.siteConfig.selectors.metadata
      )) {
        const value = await this.extractFieldValue(element, selector);
        if (value) {
          product.metadata[key] = value;
        }
      }
    }

    return product;
  }

  async extractField(element, fieldName, selector, product, normalizer = null) {
    if (!selector) return;

    const value = await this.extractFieldValue(element, selector);
    if (value) {
      product[fieldName] = normalizer
        ? normalizer(value)
        : this.normalizeText(value);
    }
  }

  async extractFieldValue(element, selector) {
    try {
      const targetElement = await element.$(selector);
      if (targetElement) {
        // Try to get text content first
        let value = await targetElement.textContent();

        // If no text content, try common attributes
        if (!value || value.trim() === "") {
          value =
            (await targetElement.getAttribute("alt")) ||
            (await targetElement.getAttribute("title")) ||
            (await targetElement.getAttribute("data-price")) ||
            (await targetElement.getAttribute("content"));
        }

        return value?.trim();
      }
    } catch (error) {
      this.logger.debug?.(
        "Error extracting field with selector ${selector}:",
        error.message
      );
    }
    return null;
  }

  normalizeText(text) {
    if (!text) return null;
    return text.trim().replace(/\s+/g, " ").replace(/\n/g, " ");
  }

  normalizePrice(priceText) {
    if (!priceText) return null;

    // Remove currency symbols and extract numeric value
    const cleaned = priceText.replace(/[^\d.,]/g, "");
    const price = parseFloat(
      cleaned.replace(/,(?=\d{3})/g, "").replace(",", ".")
    );

    return isNaN(price) ? null : price;
  }

  normalizeUrl(url, baseUrl) {
    if (!url) return null;

    try {
      return new URL(url, baseUrl).href;
    } catch {
      return url.startsWith("http") ? url : null;
    }
  }

  isValidProduct(product) {
    // Basic validation - ensure at least title or price exists
    return (
      product &&
      ((product.title && product.title.length > 0) ||
        (product.price && product.price > 0))
    );
  }

  async scrapePage(url, retryCount = 0) {
    if (!this.isUrlAllowed(url)) {
      this.logger.warn?.("URL blocked by robots.txt: ${url}") ||
        console.warn(`URL blocked by robots.txt: ${url}`);
      return [];
    }

    let page;
    try {
      page = await this.createBrowserPage();

      this.logger.info?.("Scraping page: ${url}") ||
        console.log(`Scraping page: ${url}`);
      await page.goto(url, { waitUntil: "domcontentloaded" });

      // Wait for products to load
      if (this.siteConfig.waitForSelector) {
        await page.waitForSelector(this.siteConfig.waitForSelector, {
          timeout: 15000,
        });
      }

      const products = await this.extractProductsFromPage(page, url);
      this.stats.pagesProcessed++;

      return products;
    } catch (error) {
      this.logger.error?.("Error scraping ${url}:", error.message) ||
        console.error(`Error scraping ${url}:`, error.message);

      if (retryCount < this.options.maxRetries) {
        this.logger.info?.("Retrying ${url} (attempt ${retryCount + 1})") ||
          console.log(`Retrying ${url} (attempt ${retryCount + 1})`);
        await this.delay(this.options.delay * (retryCount + 1));
        return this.scrapePage(url, retryCount + 1);
      } else {
        this.logger.error?.("Max retries exceeded for ${url}") ||
          console.error(`Max retries exceeded for ${url}`);
        return [];
      }
    } finally {
      if (page) {
        await page.close();
      }
    }
  }

  async findNextPageUrl(page) {
    if (!this.siteConfig.selectors.nextPage) return null;

    try {
      const nextElement = await page.$(this.siteConfig.selectors.nextPage);
      if (nextElement) {
        const href = await nextElement.getAttribute("href");
        return href ? this.normalizeUrl(href, page.url()) : null;
      }
    } catch (error) {
      this.logger.warn?.("Error finding next page:", error.message) ||
        console.warn("Error finding next page:", error.message);
    }

    return null;
  }

  delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }

  async scrapeAllPages(onBatchProcessed = null) {
    await this.initialize();

    try {
      const urlsToProcess = [this.siteConfig.startUrl];
      const processedUrls = new Set();
      const allProducts = [];

      while (
        urlsToProcess.length > 0 &&
        this.stats.pagesProcessed < this.options.maxPages
      ) {
        const currentUrl = urlsToProcess.shift();

        if (processedUrls.has(currentUrl)) continue;
        processedUrls.add(currentUrl);

        // Respect rate limiting
        if (processedUrls.size > 1) {
          await this.delay(this.options.delay);
        }

        const products = await this.scrapePage(currentUrl);

        if (products.length > 0) {
          allProducts.push(...products);

          // Call callback for batch processing
          if (onBatchProcessed && typeof onBatchProcessed === "function") {
            await onBatchProcessed(products);
          }

          this.logger.info?.(
            "Processed ${products.length} products from ${currentUrl}"
          ) ||
            console.log(
              `Processed ${products.length} products from ${currentUrl}`
            );
        }

        // Look for next page if pagination is enabled
        if (
          this.siteConfig.selectors.nextPage &&
          this.stats.pagesProcessed < this.options.maxPages
        ) {
          const page = await this.createBrowserPage();
          try {
            await page.goto(currentUrl, { waitUntil: "domcontentloaded" });
            const nextUrl = await this.findNextPageUrl(page);

            if (nextUrl && !processedUrls.has(nextUrl)) {
              urlsToProcess.push(nextUrl);
              this.logger.info?.("Found next page: ${nextUrl}") ||
                console.log(`Found next page: ${nextUrl}`);
            }
          } finally {
            await page.close();
          }
        }
      }

      this.logScrapingStats();
      return allProducts;
    } catch (error) {
      this.logger.error?.("Scraping failed:", error) ||
        console.error("Scraping failed:", error);
      throw error;
    } finally {
      await this.cleanup();
    }
  }

  logScrapingStats() {
    const duration = (Date.now() - this.stats.startTime) / 1000;
    const stats = {
      duration: `${duration.toFixed(2)}s`,
      pagesProcessed: this.stats.pagesProcessed,
      productsFound: this.stats.productsFound,
      productsSuccess: this.stats.productsSuccess,
      productsFailed: this.stats.productsFailed,
      successRate: `${(
        (this.stats.productsSuccess / this.stats.productsFound) *
        100
      ).toFixed(2)}%`,
    };

    this.logger.info?.("Scraping completed:", stats) ||
      console.log("Scraping completed:", stats);

    return stats;
  }

  async cleanup() {
    if (this.browser) {
      await this.browser.close();
      this.logger.info?.("Browser closed") || console.log("Browser closed");
    }
  }

  getStats() {
    return { ...this.stats };
  }
}

module.exports = WebScraperEngine;
